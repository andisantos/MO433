{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 03 \n",
    "\n",
    "* Andreza Aparecida dos Santos - RA 164213 \n",
    "* Gil Ribeiro de Carvalho - RA 225323 \n",
    "* Thamiris Coelho - RA 187506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "GDUOlZy39AM7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnBSwiZ59Ec5"
   },
   "source": [
    "## Leitura dos Dados\n",
    "\n",
    "Conjunto possui 900 dados \"normais\" e até 7 outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "_sT9RDSK9BXJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.97</td>\n",
       "      <td>1.020</td>\n",
       "      <td>-2.340</td>\n",
       "      <td>3.460</td>\n",
       "      <td>1.630</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-2.660</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>1.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.30</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>1.410</td>\n",
       "      <td>-2.160</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>1.620</td>\n",
       "      <td>3.43</td>\n",
       "      <td>-0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.62</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-1.010</td>\n",
       "      <td>1.430</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-0.880</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.38</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.731</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.87</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.576</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.793</td>\n",
       "      <td>1.55</td>\n",
       "      <td>-0.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     V1     V2     V3     V4     V5     V6     V7     V8    V9    V10\n",
       "0 -2.97  1.020 -2.340  3.460  1.630  0.157 -2.660  0.559 -5.27  1.960\n",
       "1  4.30 -0.817  1.410 -2.160  0.673  0.870 -1.220  1.620  3.43 -0.771\n",
       "2 -2.62  0.378 -1.010  1.430 -0.278 -0.384  0.613 -0.880 -2.14  0.465\n",
       "3  2.38 -0.356  0.731 -1.250  0.391  0.362 -0.817  1.000  1.85 -0.260\n",
       "4  1.87 -0.568  0.440 -0.856  0.401  0.576 -0.568  0.793  1.55 -0.412"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dados3.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8-43yaX9H3I",
    "outputId": "409d3321-586a-4329-b05e-7773c1b9a72a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(907, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "contamination = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos que existe uma contaminação de 1% nos dados, já que é um parâmetro configurável em alguns dos algorítmos implementados em Python. Isso resultaria em aproximadamente 9 outliers dentro do nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoPy2DYs9LfU"
   },
   "source": [
    "## Local Outlier Factor (por densidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "CaZsq6mm9KNQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de anomalias detectadas com 2 vizinhos: 10\n",
      "Número de anomalias detectadas com 30 vizinhos: 10\n",
      "Número de anomalias detectadas com 100 vizinhos: 10\n",
      "Número de anomalias detectadas com 300 vizinhos: 10\n"
     ]
    }
   ],
   "source": [
    "neighbors = [2, 30, 100, 300]\n",
    "iteration = 0\n",
    "\n",
    "for neighbor_number in neighbors:\n",
    "    clf = LocalOutlierFactor(n_neighbors=100, contamination=contamination)\n",
    "    lof = clf.fit_predict(data)\n",
    "    \n",
    "    #lof_anomalies = np.where(lof == -1)[0]\n",
    "    unique, counts = np.unique(lof, return_counts=True)\n",
    "    lof_clusters[iteration] = dict(zip(unique, counts))\n",
    "    print(\"Número de anomalias detectadas com {} vizinhos: {}\".format(neighbor_number,lof_clusters[iteration][-1]))\n",
    "    iteration += iteration\n",
    "\n",
    "#clf = LocalOutlierFactor(n_neighbors=100, contamination=contamination)\n",
    "#lof = clf.fit_predict(data)\n",
    "\n",
    "#lof_anomalies = np.where(lof == -1)[0]\n",
    "#unique, counts = np.unique(lof, return_counts=True)\n",
    "#lof_clusters = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Número de anomalias detectadas:\", lof_clusters[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o LOF com número variado de vizinhos (2, 30, 100 e 300) e contaminação de 1%, obtivemos 10 outliers em qualquer caso, muito próximo dos 9 esperados, mas está fixo, podendo ser restringido pela contaminação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7BxZpe4HyVB"
   },
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "nUZglXVnEaqV",
    "outputId": "0865b84a-b3a6-4000-c825-b1327cf46b02",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de anomalias detectadas com 30 estimadores: 10\n",
      "Número de anomalias detectadas com 100 estimadores: 10\n",
      "Número de anomalias detectadas com 400 estimadores: 10\n",
      "Número de anomalias detectadas com 1000 estimadores: 10\n"
     ]
    }
   ],
   "source": [
    "estimators = [30, 100, 400, 1000]\n",
    "iteration = 0\n",
    "\n",
    "for estimator in estimators:\n",
    "    clf = IsolationForest(n_estimators=estimator, random_state=42, contamination=contamination).fit(data)\n",
    "    isolation = clf.predict(data)\n",
    "    \n",
    "    #isolation_anomalies = np.where(isolation == -1)[0]\n",
    "    unique, counts = np.unique(isolation, return_counts=True)\n",
    "    isolation_clusters[iteration] = dict(zip(unique, counts))\n",
    "    print(\"Número de anomalias detectadas com {} estimadores: {}\".format(estimator,isolation_clusters[iteration][-1]))\n",
    "    iteration += iteration\n",
    "\n",
    "\n",
    "#clf = IsolationForest(random_state=42, contamination=contamination).fit(data)\n",
    "#isolation = clf.predict(data)\n",
    "\n",
    "#isolation_anomalies = np.where(isolation == -1)[0]\n",
    "#unique, counts = np.unique(isolation, return_counts=True)\n",
    "#isolation_clusters = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"Número de anomalias detectadas:\", isolation_clusters[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o Isolation Forest com número variado de estimadores (30, 100, 400 e 1000) e contaminação de 1%, obtivemos 10 outliers em qualquer caso, muito próximo dos 9 esperados, mas está fixo, podendo ser restringido pela contaminação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de anomalias detectadas com nu de 0.001: 9\n",
      "Número de anomalias detectadas com nu de 0.005: 6\n",
      "Número de anomalias detectadas com nu de 0.01: 7\n",
      "Número de anomalias detectadas com nu de 0.015: 14\n",
      "Número de anomalias detectadas com nu de 0.02: 19\n"
     ]
    }
   ],
   "source": [
    "nus = [0.001, 0.005, 0.01, 0.015, 0.02]\n",
    "iteration = 0\n",
    "\n",
    "for nu in nus:\n",
    "    clf = svm.OneClassSVM(nu=nu, kernel=\"rbf\").fit(data)\n",
    "    ol = clf.predict(data)\n",
    "\n",
    "    #ol_anomalies = np.where(ol == -1)[0]\n",
    "    unique, counts = np.unique(ol, return_counts=True)\n",
    "    ol_clusters[iteration] = dict(zip(unique, counts))\n",
    "    print(\"Número de anomalias detectadas com nu de {}: {}\".format(nu,ol_clusters[iteration][-1]))\n",
    "    iteration += iteration\n",
    "       \n",
    "#clf = svm.OneClassSVM(nu=contamination, kernel=\"rbf\").fit(data)\n",
    "#ol = clf.predict(data)\n",
    "\n",
    "#ol_anomalies = np.where(ol == -1)[0]\n",
    "#unique, counts = np.unique(ol, return_counts=True)\n",
    "#ol_clusters = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Número de anomalias detectadas:\", ol_clusters[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o One Class SVM com diferentes nu (0.001, 0.005, 0.01, 0.015 e 0.02), encontramos variados valores de outliers, observado uma queda inicial entre 0.001 e 0.005, voltando a subir já com 0.01. Constatamos que após o valor de nu de 0.01, já no valor de 0.015, o número de outliers detectado dispara, passando do valor da contaminação esperada. Consideraremos então o valor de nu de X que proprociona Y outliers, estando dentro dos valores esperados de contaminação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCan (por densidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando 2 amostras vizinhas:\n",
      "Número de anomalias detectadas com eps de 0.5: 15\n",
      "Número de anomalias detectadas com eps de 1: 7\n",
      "Número de anomalias detectadas com eps de 1.5: 7\n",
      "Número de anomalias detectadas com eps de 2: 7\n",
      "Número de anomalias detectadas com eps de 2.5: 7\n",
      "Número de anomalias detectadas com eps de 3: 7\n",
      "Número de anomalias detectadas com eps de 3.5: 5\n",
      "Número de anomalias detectadas com eps de 4: 4\n",
      "Número de anomalias detectadas com eps de 4.5: 3\n",
      "Número de anomalias detectadas com eps de 5: 1\n",
      "Utilizando 4 amostras vizinhas:\n",
      "Número de anomalias detectadas com eps de 0.5: 17\n",
      "Número de anomalias detectadas com eps de 1: 7\n",
      "Número de anomalias detectadas com eps de 1.5: 7\n",
      "Número de anomalias detectadas com eps de 2: 7\n",
      "Número de anomalias detectadas com eps de 2.5: 7\n",
      "Número de anomalias detectadas com eps de 3: 7\n",
      "Número de anomalias detectadas com eps de 3.5: 5\n",
      "Número de anomalias detectadas com eps de 4: 4\n",
      "Número de anomalias detectadas com eps de 4.5: 3\n",
      "Número de anomalias detectadas com eps de 5: 1\n",
      "Utilizando 8 amostras vizinhas:\n",
      "Número de anomalias detectadas com eps de 0.5: 20\n",
      "Número de anomalias detectadas com eps de 1: 7\n",
      "Número de anomalias detectadas com eps de 1.5: 7\n",
      "Número de anomalias detectadas com eps de 2: 7\n",
      "Número de anomalias detectadas com eps de 2.5: 7\n",
      "Número de anomalias detectadas com eps de 3: 7\n",
      "Número de anomalias detectadas com eps de 3.5: 5\n",
      "Número de anomalias detectadas com eps de 4: 4\n",
      "Número de anomalias detectadas com eps de 4.5: 3\n",
      "Número de anomalias detectadas com eps de 5: 1\n",
      "Utilizando 16 amostras vizinhas:\n",
      "Número de anomalias detectadas com eps de 0.5: 39\n",
      "Número de anomalias detectadas com eps de 1: 8\n",
      "Número de anomalias detectadas com eps de 1.5: 7\n",
      "Número de anomalias detectadas com eps de 2: 7\n",
      "Número de anomalias detectadas com eps de 2.5: 7\n",
      "Número de anomalias detectadas com eps de 3: 7\n",
      "Número de anomalias detectadas com eps de 3.5: 5\n",
      "Número de anomalias detectadas com eps de 4: 4\n",
      "Número de anomalias detectadas com eps de 4.5: 3\n",
      "Número de anomalias detectadas com eps de 5: 1\n"
     ]
    }
   ],
   "source": [
    "eps_list = [0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]\n",
    "samples_list = [2, 4, 8, 16]\n",
    "iteration = 0\n",
    "\n",
    "for samples in samples_list:\n",
    "    print(\"Utilizando {} amostras vizinhas:\".format(samples))\n",
    "    for eps in eps_list:     \n",
    "        outlier_detection = DBSCAN(min_samples = samples, eps = eps)\n",
    "        clusters = outlier_detection.fit_predict(data)\n",
    "\n",
    "        #dbscan_anomalies = np.where(clusters == -1)[0]\n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        dbscan_clusters[iteration] = dict(zip(unique, counts))\n",
    "        print(\"Número de anomalias detectadas com eps de {}: {}\".format(eps, dbscan_clusters[iteration][-1]))\n",
    "        iteration += iteration\n",
    "\n",
    "\n",
    "#outlier_detection = DBSCAN(min_samples = 2, eps = 3)\n",
    "#clusters = outlier_detection.fit_predict(data)\n",
    "\n",
    "#dbscan_anomalies = np.where(clusters == -1)[0]\n",
    "#unique, counts = np.unique(clusters, return_counts=True)\n",
    "#dbscan_clusters = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Número de anomalias detectadas:\", dbscan_clusters[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando o DBScan com variações de amostras vizinhas (2, 4, 8 e 16) e eps (0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5 e 5), constatamos que para os variados números de amostras vizinhas, dentro da faixa de eps de 1 ou 1.5 a 3, existe uma constância no valor de outliers detectados, no caso, 7, próximo dos 9 esperados com a contaminação de 1%. Portanto consideraremos o valor de 4 amostras vizinhas e eps de 2, ficando com 7 outliers, pouco abaixo da contaminação esperada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_anomalies = list(set(dbscan_anomalies) & set(ol_anomalies) & set(isolation_anomalies) & set(lof_anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de anomalias combinando os resultados: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de anomalias combinando os resultados:\", len(total_anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados anomalos encontrados combinando os resultados de todas as técnicas aplicadas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.97</td>\n",
       "      <td>1.020</td>\n",
       "      <td>-2.340</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.630</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-2.660</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-5.270</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-1.06</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-1.930</td>\n",
       "      <td>-0.709</td>\n",
       "      <td>3.400</td>\n",
       "      <td>-1.430</td>\n",
       "      <td>2.410</td>\n",
       "      <td>-1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>-3.68</td>\n",
       "      <td>-1.890</td>\n",
       "      <td>-4.730</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>1.630</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>-2.15</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>-2.070</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.527</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1     V2     V3    V4     V5     V6     V7     V8     V9   V10\n",
       "0   -2.97  1.020 -2.340  3.46  1.630  0.157 -2.660  0.559 -5.270  1.96\n",
       "358 -1.06 -0.771  0.273 -1.49 -1.930 -0.709  3.400 -1.430  2.410 -1.02\n",
       "554 -3.68 -1.890 -4.730  1.19  0.696  0.306 -0.464  1.630 -0.680  1.66\n",
       "832 -2.15  0.469 -1.350 -1.12 -1.200 -2.070  0.909  0.224  0.527  1.67"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dados anomalos encontrados combinando os resultados de todas as técnicas aplicadas\")\n",
    "data.loc[data.index.isin(total_anomalies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Trabalho_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
